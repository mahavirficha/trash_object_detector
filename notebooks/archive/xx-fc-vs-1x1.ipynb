{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Average, Conv2D, Dense, Dropout, Flatten, Input, MaxPooling2D, Reshape, TimeDistributed\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model as KerasModel\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from text_recognizer.datasets.emnist import EmnistDataset\n",
    "from text_recognizer.models.emnist_mlp import EmnistMlp\n",
    "from training.util import evaluate_model, train_model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_3 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 65)                8385      \n",
      "=================================================================\n",
      "Total params: 1,206,977\n",
      "Trainable params: 1,206,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 523449 samples, validate on 174483 samples\n",
      "Epoch 1/1\n",
      "523449/523449 [==============================] - 26s 51us/step - loss: 0.5355 - acc: 0.8233 - val_loss: 0.4230 - val_acc: 0.8527\n",
      "Training took 26.715650 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f07ab3ef898>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple lenet\n",
    "\n",
    "def lenet(image_height: int, image_width: int, num_classes: int):\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((image_height, image_width, 1), input_shape=(image_height, image_width)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "data = EmnistDataset()\n",
    "nn = lenet(28, 28, data.num_classes)\n",
    "train_model(\n",
    "    model=nn,\n",
    "    x_train=data.x_train,\n",
    "    y_train=data.y_train,\n",
    "    loss='categorical_crossentropy',\n",
    "    epochs=1,\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_5 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 1, 1, 128)         1179776   \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 1, 1, 65)          8385      \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 65)                0         \n",
      "=================================================================\n",
      "Total params: 1,206,977\n",
      "Trainable params: 1,206,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 523449 samples, validate on 174483 samples\n",
      "Epoch 1/1\n",
      "523449/523449 [==============================] - 34s 66us/step - loss: 0.5344 - acc: 0.8233 - val_loss: 0.4338 - val_acc: 0.8467\n",
      "Training took 34.620495 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f085a3299b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing FCs with all convs\n",
    "\n",
    "def lenet2(image_height: int, image_width: int, num_classes: int):\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((image_height, image_width, 1), input_shape=(image_height, image_width)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (12, 12), activation='relu'))\n",
    "    model.add(Conv2D(num_classes, (1, 1), activation='softmax'))\n",
    "    model.add(Flatten())\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "data = EmnistDataset()\n",
    "nn = lenet2(28, 28, data.num_classes)\n",
    "train_model(\n",
    "    model=nn,\n",
    "    x_train=data.x_train,\n",
    "    y_train=data.y_train,\n",
    "    loss='categorical_crossentropy',\n",
    "    epochs=1,\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 2, 28, 14, 1)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 2, 65)             518849    \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 130)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 65)                8515      \n",
      "=================================================================\n",
      "Total params: 527,364\n",
      "Trainable params: 527,364\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 523449 samples, validate on 174483 samples\n",
      "Epoch 1/1\n",
      "523449/523449 [==============================] - 26s 50us/step - loss: 2.2152 - acc: 0.4448 - val_loss: 1.4252 - val_acc: 0.5962\n",
      "Training took 26.228385 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0852e93e80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time-distributing lenet over two non-overlapping patches of the image\n",
    "\n",
    "def lenet_td(image_height: int, image_width: int, num_classes: int):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    inputs = Input(shape=(image_height, image_width))\n",
    "    reshaped_inputs = Reshape((2, image_height, image_width // 2, 1))(inputs)\n",
    "    td_outputs = TimeDistributed(model)(reshaped_inputs)\n",
    "    flat_td_outputs = Flatten()(td_outputs)\n",
    "    outputs = Dense(num_classes, activation='softmax')(flat_td_outputs)\n",
    "    model2 = KerasModel(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model2.summary()\n",
    "    return model2\n",
    "\n",
    "\n",
    "data = EmnistDataset()\n",
    "nn = lenet_td(28, 28, data.num_classes)\n",
    "train_model(\n",
    "    model=nn,\n",
    "    x_train=data.x_train,\n",
    "    y_train=data.y_train,\n",
    "    loss='categorical_crossentropy',\n",
    "    epochs=1,\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_18 (Reshape)         (None, 56, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 54, 12, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 52, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 26, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 2, 1, 128)         532608    \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 2, 1, 65)          8385      \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 130)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 65)                8515      \n",
      "=================================================================\n",
      "Total params: 568,324\n",
      "Trainable params: 568,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 523449 samples, validate on 174483 samples\n",
      "Epoch 1/1\n",
      "523449/523449 [==============================] - 34s 65us/step - loss: 2.0874 - acc: 0.4785 - val_loss: 1.1843 - val_acc: 0.6543\n",
      "Training took 34.453667 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f084fada9b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All-conv solution that does the same thing\n",
    "\n",
    "def lenet22(image_height: int, image_width: int, num_classes: int):\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((image_height * 2, image_width // 2, 1), input_shape=(image_height, image_width)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(image_height, image_width, 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (13, 5), strides=(13, 1), activation='relu'))\n",
    "    model.add(Conv2D(num_classes, (1, 1), activation='softmax'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "data = EmnistDataset()\n",
    "nn = lenet22(28, 28, data.num_classes)\n",
    "train_model(\n",
    "    model=nn,\n",
    "    x_train=data.x_train,\n",
    "    y_train=data.y_train,\n",
    "    loss='categorical_crossentropy',\n",
    "    epochs=1,\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_3 (Reshape)          (None, 56, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 54, 12, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 52, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 26, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 2, 5, 128)         639104    \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 2, 5, 65)          8385      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 650)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 65)                42315     \n",
      "=================================================================\n",
      "Total params: 708,620\n",
      "Trainable params: 708,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 523449 samples, validate on 174483 samples\n",
      "Epoch 1/1\n",
      "523449/523449 [==============================] - 36s 68us/step - loss: 1.0932 - acc: 0.7045 - val_loss: 0.5817 - val_acc: 0.8100\n",
      "Training took 35.943209 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb88ef8fda0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All-conv solution that does the same thing\n",
    "\n",
    "def lenet22(image_height: int, image_width: int, num_classes: int):\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((image_height * 2, image_width // 2, 1), input_shape=(image_height, image_width)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(image_height, image_width, 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (13, 5), strides=(13, 1), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(num_classes, (1, 1), activation='softmax'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "data = EmnistDataset()\n",
    "nn = lenet22(28, 28, data.num_classes)\n",
    "train_model(\n",
    "    model=nn,\n",
    "    x_train=data.x_train,\n",
    "    y_train=data.y_train,\n",
    "    loss='categorical_crossentropy',\n",
    "    epochs=1,\n",
    "    batch_size=128\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
