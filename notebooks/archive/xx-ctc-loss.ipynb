{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Activation, Input, Dense, Lambda, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import TerminateOnNaN\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from text_recognizer.datasets.emnist_lines import EmnistLinesDataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmnistLinesDataset loading data from HDF5...\n"
     ]
    }
   ],
   "source": [
    "dataset = EmnistLinesDataset(max_overlap=0)\n",
    "dataset.load_or_generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 32, 65)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_37 (TimeDis (None, 32, 65)            4290      \n",
      "=================================================================\n",
      "Total params: 4,290\n",
      "Trainable params: 4,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 2s 215us/step - loss: 3.5318 - acc: 0.8033\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 95us/step - loss: 2.6040 - acc: 0.9199\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 96us/step - loss: 1.8043 - acc: 0.9496\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 93us/step - loss: 1.1775 - acc: 0.9766\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 93us/step - loss: 0.7427 - acc: 0.9808\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 94us/step - loss: 0.4670 - acc: 0.9809\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 92us/step - loss: 0.2982 - acc: 0.9836\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 91us/step - loss: 0.1934 - acc: 0.9846\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 94us/step - loss: 0.1272 - acc: 0.9885\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 93us/step - loss: 0.0854 - acc: 0.9920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6b2fbb2f98>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's make sure that we can learn on the output data itself\n",
    "\n",
    "inputs = Input(shape=(32, 65))\n",
    "outputs = TimeDistributed(Dense(65, activation='softmax'))(inputs)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()\n",
    "model.compile('rmsprop', 'categorical_crossentropy', ['accuracy'])\n",
    "model.fit(x=dataset.y_train, y=dataset.y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 32, 65)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_38 (TimeDis (None, 32, 65)            4290      \n",
      "=================================================================\n",
      "Total params: 4,290\n",
      "Trainable params: 4,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 3.6139 - acc: 0.7297\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.6830 - acc: 0.9365\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.8745 - acc: 0.9604\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2278 - acc: 0.9755\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7708 - acc: 0.9808\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4803 - acc: 0.9818\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3041 - acc: 0.9837\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1963 - acc: 0.9857\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1288 - acc: 0.9884\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0861 - acc: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6b2e66ff98>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's switch to a data generator\n",
    "\n",
    "class TrivialDataset(Sequence):\n",
    "    def __init__(self, x, y, batch_size):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "\n",
    "inputs = Input(shape=(32, 65))\n",
    "outputs = TimeDistributed(Dense(65, activation='softmax'))(inputs)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()\n",
    "model.compile('rmsprop', 'categorical_crossentropy', ['accuracy'])\n",
    "generator = TrivialDataset(dataset.y_train, dataset.y_train, 32)\n",
    "model.fit_generator(generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "raw (InputLayer)             (None, 32, 65)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_36 (TimeDis (None, 32, 65)            4290      \n",
      "=================================================================\n",
      "Total params: 4,290\n",
      "Trainable params: 4,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 3.6483 - acc: 0.6695\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.7159 - acc: 0.9346\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.9016 - acc: 0.9487\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2487 - acc: 0.9720\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7861 - acc: 0.9771\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4912 - acc: 0.9822\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3116 - acc: 0.9837\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2015 - acc: 0.9841\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1324 - acc: 0.9874\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0886 - acc: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6b4d1f5828>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's name inputs\n",
    "\n",
    "class TrivialDataset(Sequence):\n",
    "    def __init__(self, x, y, batch_size):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_inputs = {\n",
    "            'raw': batch_x,\n",
    "            'argmax': np.argmax(batch_x, -1)\n",
    "        }\n",
    "        return batch_inputs, batch_y\n",
    "    \n",
    "\n",
    "input_raw = Input(shape=(32, 65), name='raw')\n",
    "input_argmax = Input(shape=(32,), name='argmax')\n",
    "outputs = TimeDistributed(Dense(65, activation='softmax'))(input_raw)\n",
    "model = Model(inputs=[input_raw, input_argmax], outputs=outputs)\n",
    "model.summary()\n",
    "model.compile('rmsprop', 'categorical_crossentropy', ['accuracy'])\n",
    "generator = TrivialDataset(dataset.y_train, dataset.y_train, 32)\n",
    "model.fit_generator(generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "raw (InputLayer)                (None, 32, 65)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "softmax_output (TimeDistributed (None, 32, 65)       4290        raw[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "loss_output (Lambda)            (None,)              0           softmax_output[0][0]             \n",
      "                                                                 raw[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "acc_output (Lambda)             (None,)              0           softmax_output[0][0]             \n",
      "                                                                 raw[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 4,290\n",
      "Trainable params: 4,290\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 15.6678 - loss_output_loss: 15.6678 - acc_output_loss: 0.6622\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 14.8935 - loss_output_loss: 14.8935 - acc_output_loss: 0.8785\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 13.1591 - loss_output_loss: 13.1591 - acc_output_loss: 0.8899\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 10.3337 - loss_output_loss: 10.3337 - acc_output_loss: 0.8942\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 7.3920 - loss_output_loss: 7.3920 - acc_output_loss: 0.9092\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 5.1382 - loss_output_loss: 5.1382 - acc_output_loss: 0.9395\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 3.5363 - loss_output_loss: 3.5363 - acc_output_loss: 0.9710\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.3399 - loss_output_loss: 2.3399 - acc_output_loss: 0.9831\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4853 - loss_output_loss: 1.4853 - acc_output_loss: 0.9837\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9475 - loss_output_loss: 0.9475 - acc_output_loss: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6b2f637748>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's name outputs and compute loss and acc directly in the network\n",
    "# Note that it's important that every model output has a corresponding entry in the data.\n",
    "\n",
    "class TrivialDataset(Sequence):\n",
    "    def __init__(self, x, y, batch_size):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_inputs = {\n",
    "            'raw': batch_x,\n",
    "            'argmax': np.argmax(batch_x, -1)\n",
    "        }\n",
    "        batch_outputs = {\n",
    "            'loss_output': batch_y,\n",
    "            'acc_output': np.argmax(batch_x, -1)\n",
    "        }\n",
    "        return batch_inputs, batch_outputs\n",
    "\n",
    "    \n",
    "input_raw = Input(shape=(32, 65), name='raw')\n",
    "input_argmax = Input(shape=(32,), name='argmax')\n",
    "\n",
    "softmax_output = TimeDistributed(Dense(65, activation='softmax'), name='softmax_output')(input_raw)\n",
    "\n",
    "loss_output = Lambda(lambda x: K.mean(K.categorical_crossentropy(x[0], x[1]), axis=-1), name='loss_output')([softmax_output, input_raw])\n",
    "acc_output = Lambda(lambda x: K.mean(K.equal(K.argmax(x[0], axis=-1), K.argmax(x[1], axis=-1)), axis=-1), name='acc_output')([softmax_output, input_raw])\n",
    "\n",
    "model = Model(inputs=[input_raw, input_argmax], outputs=[loss_output, acc_output])\n",
    "model.summary()\n",
    "model.compile('rmsprop', \n",
    "              loss={\n",
    "                  'loss_output': lambda y_true, y_pred: y_pred,\n",
    "                  'acc_output': lambda y_true, y_pred: y_pred\n",
    "              },\n",
    "              loss_weights={\n",
    "                  'loss_output': 1,\n",
    "                  'acc_output': 0\n",
    "              })\n",
    "generator = TrivialDataset(dataset.y_train, dataset.y_train, 32)\n",
    "model.fit_generator(generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "raw (InputLayer)                (None, 32, 66)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "y_true (InputLayer)             (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "y_pred (TimeDistributed)        (None, 32, 66)       4422        raw[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "ctc_loss_output (Lambda)        (None, 1)            0           y_true[0][0]                     \n",
      "                                                                 raw[0][0]                        \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "categorical_crossentropy_loss_o (None,)              0           y_pred[0][0]                     \n",
      "                                                                 raw[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "acc_output (Lambda)             (None,)              0           y_pred[0][0]                     \n",
      "                                                                 raw[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 4,422\n",
      "Trainable params: 4,422\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 9s 15ms/step - loss: 15.8458 - ctc_loss_output_loss: inf - categorical_crossentropy_loss_output_loss: 15.8458 - acc_output_loss: 0.3032\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 15.8121 - ctc_loss_output_loss: inf - categorical_crossentropy_loss_output_loss: 15.8121 - acc_output_loss: 0.4881\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 15.7605 - ctc_loss_output_loss: inf - categorical_crossentropy_loss_output_loss: 15.7605 - acc_output_loss: 0.4881\n",
      "Epoch 4/10\n",
      "457/625 [====================>.........] - ETA: 1s - loss: 15.6876 - ctc_loss_output_loss: inf - categorical_crossentropy_loss_output_loss: 15.6876 - acc_output_loss: 0.4893"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-218-228b1971c60c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m               })\n\u001b[1;32m     93\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrivialDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTerminateOnNaN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/fsdl-text-recognizer-6Tfq_pVK/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1759\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1761\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/.local/share/virtualenvs/fsdl-text-recognizer-6Tfq_pVK/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         outs = model.train_on_batch(\n\u001b[0;32m--> 190\u001b[0;31m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/fsdl-text-recognizer-6Tfq_pVK/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/fsdl-text-recognizer-6Tfq_pVK/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2895\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m     \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/fsdl-text-recognizer-6Tfq_pVK/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now we try CTC loss\n",
    "\n",
    "class TrivialDataset(Sequence):\n",
    "    def __init__(self, x, y, batch_size):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # NOTE: if not using np.take, some batches will be less than batch_size and stuff can get weird\n",
    "#         batch_x = np.take(self.x, range(idx * self.batch_size, (idx + 1) * self.batch_size), axis=0, mode='wrap')\n",
    "        batch_y = np.take(self.y, range(idx * self.batch_size, (idx + 1) * self.batch_size), axis=0, mode='wrap')\n",
    "        \n",
    "        batch_y = np.dstack((\n",
    "            batch_y,\n",
    "            np.zeros((batch_y.shape[0], batch_y.shape[1]))\n",
    "        ))\n",
    "        \n",
    "        batch_inputs = {\n",
    "            'raw': batch_y,\n",
    "            'y_true': np.argmax(batch_y, -1),\n",
    "            'input_length': np.ones((self.batch_size, 1)) * 32,\n",
    "            'label_length': np.array([np.where(batch_y[ind, :, -2] == 1)[0][0] for ind in range(self.batch_size)])\n",
    "        }\n",
    "        batch_outputs = {\n",
    "            'categorical_crossentropy_loss_output': batch_y,\n",
    "            'ctc_loss_output': batch_y,\n",
    "            'acc_output': np.argmax(batch_y, -1)\n",
    "        }\n",
    "        return batch_inputs, batch_outputs\n",
    "\n",
    "    \n",
    "from tensorflow.python.ops import ctc_ops as ctc\n",
    "\n",
    "def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n",
    "    \"\"\"Runs CTC loss algorithm on each batch element.\n",
    "    # Arguments\n",
    "        y_true: tensor `(samples, max_string_length)`\n",
    "            containing the truth labels.\n",
    "        y_pred: tensor `(samples, time_steps, num_categories)`\n",
    "            containing the prediction, or output of the softmax.\n",
    "        input_length: tensor `(samples, 1)` containing the sequence length for\n",
    "            each batch item in `y_pred`.\n",
    "        label_length: tensor `(samples, 1)` containing the sequence length for\n",
    "            each batch item in `y_true`.\n",
    "    # Returns\n",
    "        Tensor with shape (samples,1) containing the\n",
    "            CTC loss of each element.\n",
    "    \"\"\"\n",
    "    label_length = tf.to_int32(tf.squeeze(label_length, axis=-1))\n",
    "    input_length = tf.to_int32(tf.squeeze(input_length, axis=-1))\n",
    "    sparse_labels = tf.to_int32(K.ctc_label_dense_to_sparse(y_true, label_length))\n",
    "\n",
    "#     y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + 10 * K.epsilon())\n",
    "    y_pred = tf.transpose(y_pred, perm=[1, 0, 2])\n",
    "\n",
    "    return tf.expand_dims(ctc.ctc_loss(inputs=y_pred,\n",
    "                                       labels=sparse_labels,\n",
    "                                       sequence_length=input_length), 1)\n",
    "    \n",
    "    \n",
    "input_raw = Input(shape=(32, 66), name='raw')\n",
    "\n",
    "y_true = Input(shape=(32,), name='y_true')\n",
    "input_length = Input(shape=(1,), name='input_length')\n",
    "label_length = Input(shape=(1,), name='label_length')\n",
    "\n",
    "y_pred = TimeDistributed(Dense(66, activation='softmax'), name='y_pred')(input_raw)\n",
    "\n",
    "ctc_loss_output = Lambda(lambda x: K.ctc_batch_cost(x[0], x[1], x[2], x[3]), name='ctc_loss_output')([y_true, input_raw, input_length, label_length])\n",
    "categorical_crossentropy_loss_output = Lambda(lambda x: K.mean(K.categorical_crossentropy(x[0], x[1]), axis=-1), name='categorical_crossentropy_loss_output')([y_pred, input_raw])\n",
    "acc_output = Lambda(lambda x: K.mean(K.equal(K.argmax(x[0], axis=-1), K.argmax(x[1], axis=-1)), axis=-1), name='acc_output')([y_pred, input_raw])\n",
    "\n",
    "model = Model(inputs=[input_raw, y_true, input_length, label_length],\n",
    "              outputs=[ctc_loss_output, categorical_crossentropy_loss_output, acc_output])\n",
    "model.summary()\n",
    "\n",
    "optimizer = SGD(lr=0.001, clipnorm=5)\n",
    "model.compile(optimizer,\n",
    "              loss={\n",
    "                  'ctc_loss_output': lambda y_true, y_pred: y_pred,\n",
    "                  'categorical_crossentropy_loss_output': lambda y_true, y_pred: y_pred,\n",
    "                  'acc_output': lambda y_true, y_pred: y_pred\n",
    "              },\n",
    "              loss_weights={\n",
    "                  'ctc_loss_output': 0,\n",
    "                  'categorical_crossentropy_loss_output': 1,\n",
    "                  'acc_output': 0\n",
    "              })\n",
    "generator = TrivialDataset(dataset.y_train, dataset.y_train, 16)\n",
    "model.fit_generator(generator, epochs=10, callbacks=[TerminateOnNaN()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
